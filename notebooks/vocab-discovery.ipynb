{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636.55859375"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.Process(os.getpid()).memory_info().rss / 1024 / 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/AmazonSageMaker-bluewater-nlp'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_fp = '../pretrained/rebuild.vectors.npy'\n",
    "vocab_fp = '../pretrained/rebuild.vocab.txt'\n",
    "dataset_vocab_fp = '../wrk/restroom-dataset.v2.vocab.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196622, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_arr = np.load(emb_fp)\n",
    "emb_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196622,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(vocab_fp) as inp:\n",
    "    vocab_arr = [l.rstrip() for l in inp]\n",
    "vocab_arr = np.array(vocab_arr)\n",
    "vocab_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos(w):\n",
    "    i = w.rfind('_')\n",
    "    return w[i+1:] if i > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN     86861\n",
       "ADJ      31561\n",
       "X        31544\n",
       "PROPN    25945\n",
       "VERB     16321\n",
       "ADV       4194\n",
       "INTJ       137\n",
       "NUM         57\n",
       "NaN          2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_pos_freq_ss = pd.Series(Counter(get_pos(w) for w in vocab_arr)).sort_values(ascending=False)\n",
    "vocab_pos_freq_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NOUN     0.441766\n",
       "ADJ      0.160516\n",
       "X        0.160430\n",
       "PROPN    0.131954\n",
       "VERB     0.083007\n",
       "ADV      0.021330\n",
       "INTJ     0.000697\n",
       "NUM      0.000290\n",
       "NaN      0.000010\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_pos_freq_ss / vocab_pos_freq_ss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a function to get the most similar words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_idx = {\n",
    "    w : i\n",
    "    for i, w in enumerate(vocab_arr)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_words(w, n_top=15):\n",
    "    w_i = vocab_idx.get(w, -1)\n",
    "    if w_i < 0:\n",
    "        # TODO list suggestions using argmin over edit distance\n",
    "        raise ValueError(\"Can't find word '%s' in the vocab\" % w)\n",
    "    w_emb = emb_arr[w_i]\n",
    "    dist_arr = np.sqrt(np.power(emb_arr - w_emb, 2).sum(-1))\n",
    "    top_indices = np.argpartition(dist_arr, n_top)[:n_top]\n",
    "    top_distances = dist_arr[top_indices]\n",
    "    return pd.Series(top_distances, index=vocab_arr[top_indices]).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "хуй_NOUN        0.000000\n",
       "хер_NOUN        0.518857\n",
       "пизда_NOUN      0.656288\n",
       "жопа_NOUN       0.658848\n",
       "залупа_NOUN     0.701741\n",
       "ебать_VERB      0.710420\n",
       "срака_NOUN      0.724436\n",
       "писюн_NOUN      0.736951\n",
       "писька_NOUN     0.740310\n",
       "блять_VERB      0.749357\n",
       "блядь_NOUN      0.752477\n",
       "бля_INTJ        0.758907\n",
       "дрочить_VERB    0.762496\n",
       "задница_NOUN    0.776444\n",
       "ебаться_VERB    0.782574\n",
       "dtype: float32"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_words('хуй_NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate OOV in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "181"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_vocab_ss = pd.read_csv(dataset_vocab_fp, header=None, squeeze=True, index_col=0)\n",
    "dataset_vocab_ss.index.name = 'Token'\n",
    "dataset_vocab_ss.name = 'Frequency'\n",
    "dataset_vocab_ss.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token\n",
       "я_PRON                   21\n",
       "в_ADP                    15\n",
       "не_PART                   7\n",
       "опять_ADV                 7\n",
       "сейчас_ADV                5\n",
       "кто_PRON                  5\n",
       "на_ADP                    4\n",
       "мой_DET                   3\n",
       "такой_DET                 3\n",
       "какой_DET                 3\n",
       "как_SCONJ                 3\n",
       "из_ADP                    3\n",
       "ну_PART                   3\n",
       "никогда_ADV               2\n",
       "он_PRON                   2\n",
       "как_ADV                   2\n",
       "и_SCONJ                   2\n",
       "за_ADP                    2\n",
       "все_PRON                  2\n",
       "вот_PART                  2\n",
       "быть_VERB                 2\n",
       "уже_ADV                   2\n",
       "то_PART                   2\n",
       "только_PART               2\n",
       "у_ADP                     1\n",
       "еще_ADV                   1\n",
       "ебаша_NOUN                1\n",
       "тут_ADV                   1\n",
       "ты_PRON                   1\n",
       "дыка_NOUN                 1\n",
       "тот_DET                   1\n",
       "когда_SCONJ               1\n",
       "футбок_NOUN               1\n",
       "что_SCONJ                 1\n",
       "врота_NOUN                1\n",
       "что_PRON                  1\n",
       "всегда_ADV                1\n",
       "вы_PRON                   1\n",
       "готов_NOUN                1\n",
       "грильвуд_NOUN             1\n",
       "да_PART                   1\n",
       "потеребоникать_VERB       1\n",
       "привязять_NOUN            1\n",
       "релайксировать_VERB       1\n",
       "санэпедемстанция_NOUN     1\n",
       "сейрьезно_ADV             1\n",
       "перед_ADP                 1\n",
       "очерядь_ADV               1\n",
       "ли_PART                   1\n",
       "лососнуть_VERB            1\n",
       "там_PART                  1\n",
       "надо_ADV                  1\n",
       "наебашить_VERB            1\n",
       "напрудить_VERB            1\n",
       "стыднно_ADV               1\n",
       "обосслася_NOUN            1\n",
       "это_PART                  1\n",
       "оно_PRON                  1\n",
       "а_SCONJ                   1\n",
       "Name: Frequency, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_vocab_ss[~dataset_vocab_ss.index.isin(vocab_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
