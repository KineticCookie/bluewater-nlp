{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTENT_LABELS = [\n",
    "    'Book',\n",
    "    'CheckStatus',\n",
    "    'GoToHell',\n",
    "    'OMG',\n",
    "    'Other'\n",
    "]\n",
    "NUM_INTENTS = len(INTENT_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    tokens = features['tokens']\n",
    "    token_lengths = features['token_lengths']\n",
    "    intent_logits = tf.random_uniform((tf.shape(tokens)[0], NUM_INTENTS), maxval=10.)\n",
    "    intent_proba = tf.nn.softmax(intent_logits)\n",
    "    intent_i = tf.argmax(intent_proba, axis=-1)\n",
    "    intent_confidence = tf.reduce_max(intent_proba, axis=-1)\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        label_lookup = tf.contrib.lookup.index_to_string_table_from_tensor(INTENT_LABELS, \n",
    "                                                                           default_value=INTENT_LABELS[-1])\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions={\n",
    "            'intent_i' : intent_i,\n",
    "            'confidence' : intent_confidence,\n",
    "            'input_length' : token_lengths,\n",
    "            'intent' : label_lookup.lookup(intent_i)\n",
    "        })\n",
    "    elif mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "        train_op = tf.assign_add(global_step, 1)\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=tf.constant(0), train_op=train_op)\n",
    "    else:\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_input_fn():\n",
    "    return ({\n",
    "        'tokens' : tf.constant([['Я', 'хочу', 'поссать']]),\n",
    "        'token_lengths' : tf.constant([3])\n",
    "    }, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_fn():\n",
    "    # we expect a single message only (no batches) from an upstream model\n",
    "    receiver_msg_ph = tf.placeholder(tf.string, (None,))\n",
    "    return tf.estimator.export.ServingInputReceiver(features = {\n",
    "        # but the model fn works with batches\n",
    "        'tokens' : tf.expand_dims(receiver_msg_ph, axis=0),\n",
    "        'token_lengths' : tf.expand_dims(tf.shape(receiver_msg_ph)[0], axis=0)\n",
    "    }, receiver_tensors = {\n",
    "        'preprocessed_msg' : receiver_msg_ph\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf wrk/baseline-v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'wrk/baseline-v0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fa54fd18438>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.estimator.Estimator(model_fn, model_dir='wrk/baseline-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into wrk/baseline-v0/model.ckpt.\n",
      "INFO:tensorflow:loss = 0, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 1 into wrk/baseline-v0/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7fa54fd18e10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(fake_input_fn, max_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from wrk/baseline-v0/model.ckpt-1\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'intent_i': 2,\n",
       "  'confidence': 0.5903566,\n",
       "  'input_length': 3,\n",
       "  'intent': b'GoToHell'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in estimator.predict(tf.estimator.inputs.numpy_input_fn({\n",
    "    'tokens' : np.array([['Я', 'хочц', 'поссикать', 'gfdgf']]),\n",
    "    'token_lengths' : np.array([3])\n",
    "}, shuffle=False))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from wrk/baseline-v0/model.ckpt-1\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved-models/temp-b'1545335768'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'saved-models/1545335768'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.export_savedmodel('saved-models', serving_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
